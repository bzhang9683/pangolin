{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon #4\n",
    "\n",
    "Written by Eleanor Quint\n",
    "\n",
    "Topics: \n",
    "- Convolutional layers\n",
    "- Pooling layers\n",
    "\n",
    "This is all setup in a IPython notebook so you can run any code you want to experiment with. Feel free to edit any cell, or add some to run your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll start with our library imports...\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np                 # to use numpy arrays\n",
    "import tensorflow as tf            # to specify and run computation graphs\n",
    "import tensorflow_datasets as tfds # to load training data\n",
    "import matplotlib.pyplot as plt    # to visualize data and draw plots\n",
    "from tqdm import tqdm              # to track progress of loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this hackathon, we'll be using convolutional layers, which are uniquely suited to working with image data. We'll use a dataset which is much more challenging if you're only using dense layers, [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<00:14, 1974.04 examples/s]\u001b[A\n",
      "Generating train examples...:  44%|████▍     | 22149/50000 [00:11<00:14, 1984.20 examples/s]\u001b[A\n",
      "Generating train examples...:  45%|████▍     | 22355/50000 [00:11<00:13, 2005.63 examples/s]\u001b[A\n",
      "Generating train examples...:  45%|████▌     | 22558/50000 [00:11<00:13, 2012.14 examples/s]\u001b[A\n",
      "Generating train examples...:  46%|████▌     | 22762/50000 [00:11<00:13, 2020.19 examples/s]\u001b[A\n",
      "Generating train examples...:  46%|████▌     | 22967/50000 [00:11<00:13, 2028.26 examples/s]\u001b[A\n",
      "Generating train examples...:  46%|████▋     | 23171/50000 [00:11<00:13, 2030.52 examples/s]\u001b[A\n",
      "Generating train examples...:  47%|████▋     | 23378/50000 [00:12<00:13, 2041.90 examples/s]\u001b[A\n",
      "Generating train examples...:  47%|████▋     | 23585/50000 [00:12<00:12, 2047.84 examples/s]\u001b[A\n",
      "Generating train examples...:  48%|████▊     | 23790/50000 [00:12<00:12, 2045.42 examples/s]\u001b[A\n",
      "Generating train examples...:  48%|████▊     | 23995/50000 [00:12<00:12, 2041.50 examples/s]\u001b[A\n",
      "Generating train examples...:  48%|████▊     | 24200/50000 [00:12<00:12, 2041.84 examples/s]\u001b[A\n",
      "Generating train examples...:  49%|████▉     | 24405/50000 [00:12<00:12, 2043.10 examples/s]\u001b[A\n",
      "Generating train examples...:  49%|████▉     | 24610/50000 [00:12<00:12, 2043.62 examples/s]\u001b[A\n",
      "Generating train examples...:  50%|████▉     | 24815/50000 [00:12<00:12, 2038.49 examples/s]\u001b[A\n",
      "Generating train examples...:  50%|█████     | 25021/50000 [00:12<00:12, 2043.66 examples/s]\u001b[A\n",
      "Generating train examples...:  50%|█████     | 25226/50000 [00:12<00:12, 2036.44 examples/s]\u001b[A\n",
      "Generating train examples...:  51%|█████     | 25430/50000 [00:13<00:12, 2036.68 examples/s]\u001b[A\n",
      "Generating train examples...:  51%|█████▏    | 25636/50000 [00:13<00:11, 2041.33 examples/s]\u001b[A\n",
      "Generating train examples...:  52%|█████▏    | 25841/50000 [00:13<00:11, 2038.30 examples/s]\u001b[A\n",
      "Generating train examples...:  52%|█████▏    | 26046/50000 [00:13<00:11, 2040.20 examples/s]\u001b[A\n",
      "Generating train examples...:  53%|█████▎    | 26251/50000 [00:13<00:11, 2039.85 examples/s]\u001b[A\n",
      "Generating train examples...:  53%|█████▎    | 26458/50000 [00:13<00:11, 2048.44 examples/s]\u001b[A\n",
      "Generating train examples...:  53%|█████▎    | 26665/50000 [00:13<00:11, 2053.44 examples/s]\u001b[A\n",
      "Generating train examples...:  54%|█████▎    | 26871/50000 [00:13<00:11, 2038.84 examples/s]\u001b[A\n",
      "Generating train examples...:  54%|█████▍    | 27075/50000 [00:13<00:11, 2031.09 examples/s]\u001b[A\n",
      "Generating train examples...:  55%|█████▍    | 27279/50000 [00:13<00:11, 2026.33 examples/s]\u001b[A\n",
      "Generating train examples...:  55%|█████▍    | 27482/50000 [00:14<00:11, 2026.82 examples/s]\u001b[A\n",
      "Generating train examples...:  55%|█████▌    | 27685/50000 [00:14<00:11, 2023.30 examples/s]\u001b[A\n",
      "Generating train examples...:  56%|█████▌    | 27888/50000 [00:14<00:11, 2008.22 examples/s]\u001b[A\n",
      "Generating train examples...:  56%|█████▌    | 28089/50000 [00:14<00:10, 1997.24 examples/s]\u001b[A\n",
      "Generating train examples...:  57%|█████▋    | 28291/50000 [00:14<00:10, 2003.73 examples/s]\u001b[A\n",
      "Generating train examples...:  57%|█████▋    | 28495/50000 [00:14<00:10, 2013.71 examples/s]\u001b[A\n",
      "Generating train examples...:  57%|█████▋    | 28700/50000 [00:14<00:10, 2023.67 examples/s]\u001b[A\n",
      "Generating train examples...:  58%|█████▊    | 28904/50000 [00:14<00:10, 2027.48 examples/s]\u001b[A\n",
      "Generating train examples...:  58%|█████▊    | 29111/50000 [00:14<00:10, 2038.85 examples/s]\u001b[A\n",
      "Generating train examples...:  59%|█████▊    | 29317/50000 [00:15<00:10, 2042.64 examples/s]\u001b[A\n",
      "Generating train examples...:  59%|█████▉    | 29522/50000 [00:15<00:10, 2036.93 examples/s]\u001b[A\n",
      "Generating train examples...:  59%|█████▉    | 29730/50000 [00:15<00:09, 2047.81 examples/s]\u001b[A\n",
      "Generating train examples...:  60%|█████▉    | 29935/50000 [00:15<00:09, 2040.31 examples/s]\u001b[A\n",
      "Generating train examples...:  60%|██████    | 30140/50000 [00:15<00:10, 1879.51 examples/s]\u001b[A\n",
      "Generating train examples...:  61%|██████    | 30349/50000 [00:15<00:10, 1938.40 examples/s]\u001b[A\n",
      "Generating train examples...:  61%|██████    | 30555/50000 [00:15<00:09, 1971.33 examples/s]\u001b[A\n",
      "Generating train examples...:  62%|██████▏   | 30761/50000 [00:15<00:09, 1996.56 examples/s]\u001b[A\n",
      "Generating train examples...:  62%|██████▏   | 30968/50000 [00:15<00:09, 2017.61 examples/s]\u001b[A\n",
      "Generating train examples...:  62%|██████▏   | 31171/50000 [00:15<00:09, 1974.68 examples/s]\u001b[A\n",
      "Generating train examples...:  63%|██████▎   | 31370/50000 [00:16<00:09, 1955.32 examples/s]\u001b[A\n",
      "Generating train examples...:  63%|██████▎   | 31570/50000 [00:16<00:09, 1966.48 examples/s]\u001b[A\n",
      "Generating train examples...:  64%|██████▎   | 31768/50000 [00:16<00:09, 1967.35 examples/s]\u001b[A\n",
      "Generating train examples...:  64%|██████▍   | 31971/50000 [00:16<00:09, 1984.70 examples/s]\u001b[A\n",
      "Generating train examples...:  64%|██████▍   | 32170/50000 [00:16<00:08, 1981.82 examples/s]\u001b[A\n",
      "Generating train examples...:  65%|██████▍   | 32372/50000 [00:16<00:08, 1991.74 examples/s]\u001b[A\n",
      "Generating train examples...:  65%|██████▌   | 32572/50000 [00:16<00:08, 1947.74 examples/s]\u001b[A\n",
      "Generating train examples...:  66%|██████▌   | 32768/50000 [00:16<00:08, 1938.77 examples/s]\u001b[A\n",
      "Generating train examples...:  66%|██████▌   | 32974/50000 [00:16<00:08, 1973.11 examples/s]\u001b[A\n",
      "Generating train examples...:  66%|██████▋   | 33177/50000 [00:16<00:08, 1987.96 examples/s]\u001b[A\n",
      "Generating train examples...:  67%|██████▋   | 33376/50000 [00:17<00:08, 1961.61 examples/s]\u001b[A\n",
      "Generating train examples...:  67%|██████▋   | 33575/50000 [00:17<00:08, 1967.45 examples/s]\u001b[A\n",
      "Generating train examples...:  68%|██████▊   | 33782/50000 [00:17<00:08, 1996.62 examples/s]\u001b[A\n",
      "Generating train examples...:  68%|██████▊   | 33985/50000 [00:17<00:07, 2004.13 examples/s]\u001b[A\n",
      "Generating train examples...:  68%|██████▊   | 34186/50000 [00:17<00:08, 1955.27 examples/s]\u001b[A\n",
      "Generating train examples...:  69%|██████▉   | 34382/50000 [00:17<00:07, 1955.14 examples/s]\u001b[A\n",
      "Generating train examples...:  69%|██████▉   | 34591/50000 [00:17<00:07, 1993.22 examples/s]\u001b[A\n",
      "Generating train examples...:  70%|██████▉   | 34797/50000 [00:17<00:07, 2012.00 examples/s]\u001b[A\n",
      "Generating train examples...:  70%|███████   | 35001/50000 [00:17<00:07, 2017.68 examples/s]\u001b[A\n",
      "Generating train examples...:  70%|███████   | 35203/50000 [00:17<00:07, 1971.30 examples/s]\u001b[A\n",
      "Generating train examples...:  71%|███████   | 35402/50000 [00:18<00:07, 1975.67 examples/s]\u001b[A\n",
      "Generating train examples...:  71%|███████   | 35606/50000 [00:18<00:07, 1992.10 examples/s]\u001b[A\n",
      "Generating train examples...:  72%|███████▏  | 35810/50000 [00:18<00:07, 2004.75 examples/s]\u001b[A\n",
      "Generating train examples...:  72%|███████▏  | 36015/50000 [00:18<00:06, 2017.11 examples/s]\u001b[A\n",
      "Generating train examples...:  72%|███████▏  | 36220/50000 [00:18<00:06, 2026.10 examples/s]\u001b[A\n",
      "Generating train examples...:  73%|███████▎  | 36423/50000 [00:18<00:06, 2023.72 examples/s]\u001b[A\n",
      "Generating train examples...:  73%|███████▎  | 36629/50000 [00:18<00:06, 2032.12 examples/s]\u001b[A\n",
      "Generating train examples...:  74%|███████▎  | 36834/50000 [00:18<00:06, 2036.20 examples/s]\u001b[A\n",
      "Generating train examples...:  74%|███████▍  | 37038/50000 [00:18<00:06, 2024.08 examples/s]\u001b[A\n",
      "Generating train examples...:  74%|███████▍  | 37241/50000 [00:18<00:06, 2022.01 examples/s]\u001b[A\n",
      "Generating train examples...:  75%|███████▍  | 37444/50000 [00:19<00:06, 2016.01 examples/s]\u001b[A\n",
      "Generating train examples...:  75%|███████▌  | 37649/50000 [00:19<00:06, 2024.67 examples/s]\u001b[A\n",
      "Generating train examples...:  76%|███████▌  | 37854/50000 [00:19<00:05, 2030.66 examples/s]\u001b[A\n",
      "Generating train examples...:  76%|███████▌  | 38058/50000 [00:19<00:05, 2023.23 examples/s]\u001b[A\n",
      "Generating train examples...:  77%|███████▋  | 38261/50000 [00:19<00:05, 1976.80 examples/s]\u001b[A\n",
      "Generating train examples...:  77%|███████▋  | 38459/50000 [00:19<00:05, 1950.38 examples/s]\u001b[A\n",
      "Generating train examples...:  77%|███████▋  | 38655/50000 [00:19<00:05, 1936.40 examples/s]\u001b[A\n",
      "Generating train examples...:  78%|███████▊  | 38849/50000 [00:19<00:05, 1924.97 examples/s]\u001b[A\n",
      "Generating train examples...:  78%|███████▊  | 39042/50000 [00:19<00:05, 1860.20 examples/s]\u001b[A\n",
      "Generating train examples...:  78%|███████▊  | 39247/50000 [00:20<00:05, 1912.97 examples/s]\u001b[A\n",
      "Generating train examples...:  79%|███████▉  | 39439/50000 [00:20<00:05, 1901.40 examples/s]\u001b[A\n",
      "Generating train examples...:  79%|███████▉  | 39630/50000 [00:20<00:05, 1836.17 examples/s]\u001b[A\n",
      "Generating train examples...:  80%|███████▉  | 39815/50000 [00:20<00:05, 1786.27 examples/s]\u001b[A\n",
      "Generating train examples...:  80%|███████▉  | 39995/50000 [00:20<00:05, 1761.82 examples/s]\u001b[A\n",
      "Generating train examples...:  80%|████████  | 40172/50000 [00:20<00:06, 1626.34 examples/s]\u001b[A\n",
      "Generating train examples...:  81%|████████  | 40344/50000 [00:20<00:05, 1647.74 examples/s]\u001b[A\n",
      "Generating train examples...:  81%|████████  | 40511/50000 [00:20<00:05, 1649.56 examples/s]\u001b[A\n",
      "Generating train examples...:  81%|████████▏ | 40693/50000 [00:20<00:05, 1696.44 examples/s]\u001b[A\n",
      "Generating train examples...:  82%|████████▏ | 40893/50000 [00:20<00:05, 1782.39 examples/s]\u001b[A\n",
      "Generating train examples...:  82%|████████▏ | 41073/50000 [00:21<00:05, 1745.25 examples/s]\u001b[A\n",
      "Generating train examples...:  83%|████████▎ | 41273/50000 [00:21<00:04, 1818.89 examples/s]\u001b[A\n",
      "Generating train examples...:  83%|████████▎ | 41477/50000 [00:21<00:04, 1881.49 examples/s]\u001b[A\n",
      "Generating train examples...:  83%|████████▎ | 41682/50000 [00:21<00:04, 1930.57 examples/s]\u001b[A\n",
      "Generating train examples...:  84%|████████▍ | 41877/50000 [00:21<00:04, 1935.23 examples/s]\u001b[A\n",
      "Generating train examples...:  84%|████████▍ | 42071/50000 [00:21<00:04, 1847.24 examples/s]\u001b[A\n",
      "Generating train examples...:  85%|████████▍ | 42257/50000 [00:21<00:04, 1829.85 examples/s]\u001b[A\n",
      "Generating train examples...:  85%|████████▍ | 42441/50000 [00:21<00:04, 1755.61 examples/s]\u001b[A\n",
      "Generating train examples...:  85%|████████▌ | 42618/50000 [00:21<00:04, 1755.21 examples/s]\u001b[A\n",
      "Generating train examples...:  86%|████████▌ | 42814/50000 [00:22<00:03, 1813.38 examples/s]\u001b[A\n",
      "Generating train examples...:  86%|████████▌ | 43013/50000 [00:22<00:03, 1863.09 examples/s]\u001b[A\n",
      "Generating train examples...:  86%|████████▋ | 43200/50000 [00:22<00:03, 1795.63 examples/s]\u001b[A\n",
      "Generating train examples...:  87%|████████▋ | 43381/50000 [00:22<00:03, 1770.06 examples/s]\u001b[A\n",
      "Generating train examples...:  87%|████████▋ | 43560/50000 [00:22<00:03, 1775.77 examples/s]\u001b[A\n",
      "Generating train examples...:  87%|████████▋ | 43745/50000 [00:22<00:03, 1796.24 examples/s]\u001b[A\n",
      "Generating train examples...:  88%|████████▊ | 43933/50000 [00:22<00:03, 1820.64 examples/s]\u001b[A\n",
      "Generating train examples...:  88%|████████▊ | 44116/50000 [00:22<00:03, 1821.72 examples/s]\u001b[A\n",
      "Generating train examples...:  89%|████████▊ | 44304/50000 [00:22<00:03, 1834.96 examples/s]\u001b[A\n",
      "Generating train examples...:  89%|████████▉ | 44495/50000 [00:22<00:02, 1857.01 examples/s]\u001b[A\n",
      "Generating train examples...:  89%|████████▉ | 44681/50000 [00:23<00:02, 1838.47 examples/s]\u001b[A\n",
      "Generating train examples...:  90%|████████▉ | 44866/50000 [00:23<00:02, 1840.28 examples/s]\u001b[A\n",
      "Generating train examples...:  90%|█████████ | 45052/50000 [00:23<00:02, 1844.99 examples/s]\u001b[A\n",
      "Generating train examples...:  90%|█████████ | 45243/50000 [00:23<00:02, 1863.09 examples/s]\u001b[A\n",
      "Generating train examples...:  91%|█████████ | 45442/50000 [00:23<00:02, 1900.25 examples/s]\u001b[A\n",
      "Generating train examples...:  91%|█████████▏| 45633/50000 [00:23<00:02, 1888.96 examples/s]\u001b[A\n",
      "Generating train examples...:  92%|█████████▏| 45822/50000 [00:23<00:02, 1830.15 examples/s]\u001b[A\n",
      "Generating train examples...:  92%|█████████▏| 46006/50000 [00:23<00:02, 1817.24 examples/s]\u001b[A\n",
      "Generating train examples...:  92%|█████████▏| 46188/50000 [00:23<00:02, 1816.76 examples/s]\u001b[A\n",
      "Generating train examples...:  93%|█████████▎| 46370/50000 [00:23<00:02, 1788.57 examples/s]\u001b[A\n",
      "Generating train examples...:  93%|█████████▎| 46554/50000 [00:24<00:01, 1801.68 examples/s]\u001b[A\n",
      "Generating train examples...:  93%|█████████▎| 46738/50000 [00:24<00:01, 1810.11 examples/s]\u001b[A\n",
      "Generating train examples...:  94%|█████████▍| 46920/50000 [00:24<00:01, 1810.88 examples/s]\u001b[A\n",
      "Generating train examples...:  94%|█████████▍| 47105/50000 [00:24<00:01, 1820.63 examples/s]\u001b[A\n",
      "Generating train examples...:  95%|█████████▍| 47297/50000 [00:24<00:01, 1848.43 examples/s]\u001b[A\n",
      "Generating train examples...:  95%|█████████▍| 47486/50000 [00:24<00:01, 1859.72 examples/s]\u001b[A\n",
      "Generating train examples...:  95%|█████████▌| 47673/50000 [00:24<00:01, 1842.16 examples/s]\u001b[A\n",
      "Generating train examples...:  96%|█████████▌| 47858/50000 [00:24<00:01, 1841.37 examples/s]\u001b[A\n",
      "Generating train examples...:  96%|█████████▌| 48051/50000 [00:24<00:01, 1867.58 examples/s]\u001b[A\n",
      "Generating train examples...:  96%|█████████▋| 48244/50000 [00:24<00:00, 1884.18 examples/s]\u001b[A\n",
      "Generating train examples...:  97%|█████████▋| 48439/50000 [00:25<00:00, 1901.67 examples/s]\u001b[A\n",
      "Generating train examples...:  97%|█████████▋| 48630/50000 [00:25<00:00, 1812.06 examples/s]\u001b[A\n",
      "Generating train examples...:  98%|█████████▊| 48813/50000 [00:25<00:00, 1777.00 examples/s]\u001b[A\n",
      "Generating train examples...:  98%|█████████▊| 48992/50000 [00:25<00:00, 1763.52 examples/s]\u001b[A\n",
      "Generating train examples...:  98%|█████████▊| 49169/50000 [00:25<00:00, 1731.69 examples/s]\u001b[A\n",
      "Generating train examples...:  99%|█████████▊| 49343/50000 [00:25<00:00, 1725.05 examples/s]\u001b[A\n",
      "Generating train examples...:  99%|█████████▉| 49534/50000 [00:25<00:00, 1778.24 examples/s]\u001b[A\n",
      "Generating train examples...:  99%|█████████▉| 49720/50000 [00:25<00:00, 1800.27 examples/s]\u001b[A\n",
      "Generating train examples...: 100%|█████████▉| 49901/50000 [00:25<00:00, 1787.77 examples/s]\u001b[A\n",
      "                                                                                            \u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:   0%|          | 0/50000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:   9%|▉         | 4543/50000 [00:00<00:01, 45414.13 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  21%|██        | 10357/50000 [00:00<00:00, 52894.73 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  37%|███▋      | 18305/50000 [00:00<00:00, 65031.49 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  53%|█████▎    | 26612/50000 [00:00<00:00, 72143.76 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  70%|██████▉   | 34938/50000 [00:00<00:00, 76149.84 examples/s]\u001b[A\n",
      "Shuffling cifar10-train.tfrecord...:  85%|████████▌ | 42554/50000 [00:00<00:00, 75000.78 examples/s]\u001b[A\n",
      "Generating splits...:  50%|█████     | 1/2 [00:26<00:26, 26.69s/ splits]\n",
      "Generating test examples...:   0%|          | 0/10000 [00:00<?, ? examples/s]\u001b[A\n",
      "Generating test examples...:   1%|          | 67/10000 [00:00<00:14, 669.14 examples/s]\u001b[A\n",
      "Generating test examples...:   3%|▎         | 259/10000 [00:00<00:06, 1402.29 examples/s]\u001b[A\n",
      "Generating test examples...:   5%|▍         | 461/10000 [00:00<00:05, 1681.44 examples/s]\u001b[A\n",
      "Generating test examples...:   6%|▋         | 647/10000 [00:00<00:05, 1749.37 examples/s]\u001b[A\n",
      "Generating test examples...:   8%|▊         | 826/10000 [00:00<00:05, 1762.19 examples/s]\u001b[A\n",
      "Generating test examples...:  10%|█         | 1010/10000 [00:00<00:05, 1786.87 examples/s]\u001b[A\n",
      "Generating test examples...:  12%|█▏        | 1192/10000 [00:00<00:04, 1794.62 examples/s]\u001b[A\n",
      "Generating test examples...:  14%|█▍        | 1375/10000 [00:00<00:04, 1805.41 examples/s]\u001b[A\n",
      "Generating test examples...:  16%|█▌        | 1556/10000 [00:00<00:04, 1799.29 examples/s]\u001b[A\n",
      "Generating test examples...:  18%|█▊        | 1753/10000 [00:01<00:04, 1849.64 examples/s]\u001b[A\n",
      "Generating test examples...:  20%|█▉        | 1953/10000 [00:01<00:04, 1895.36 examples/s]\u001b[A\n",
      "Generating test examples...:  22%|██▏       | 2157/10000 [00:01<00:04, 1938.58 examples/s]\u001b[A\n",
      "Generating test examples...:  24%|██▎       | 2359/10000 [00:01<00:03, 1963.12 examples/s]\u001b[A\n",
      "Generating test examples...:  26%|██▌       | 2556/10000 [00:01<00:03, 1952.34 examples/s]\u001b[A\n",
      "Generating test examples...:  28%|██▊       | 2752/10000 [00:01<00:03, 1946.14 examples/s]\u001b[A\n",
      "Generating test examples...:  30%|██▉       | 2954/10000 [00:01<00:03, 1967.24 examples/s]\u001b[A\n",
      "Generating test examples...:  32%|███▏      | 3160/10000 [00:01<00:03, 1994.00 examples/s]\u001b[A\n",
      "Generating test examples...:  34%|███▎      | 3368/10000 [00:01<00:03, 2017.54 examples/s]\u001b[A\n",
      "Generating test examples...:  36%|███▌      | 3570/10000 [00:01<00:03, 1968.18 examples/s]\u001b[A\n",
      "Generating test examples...:  38%|███▊      | 3769/10000 [00:02<00:03, 1973.31 examples/s]\u001b[A\n",
      "Generating test examples...:  40%|███▉      | 3972/10000 [00:02<00:03, 1989.69 examples/s]\u001b[A\n",
      "Generating test examples...:  42%|████▏     | 4177/10000 [00:02<00:02, 2005.37 examples/s]\u001b[A\n",
      "Generating test examples...:  44%|████▍     | 4382/10000 [00:02<00:02, 2016.72 examples/s]\u001b[A\n",
      "Generating test examples...:  46%|████▌     | 4584/10000 [00:02<00:02, 2013.40 examples/s]\u001b[A\n",
      "Generating test examples...:  48%|████▊     | 4786/10000 [00:02<00:02, 1983.91 examples/s]\u001b[A\n",
      "Generating test examples...:  50%|████▉     | 4985/10000 [00:02<00:02, 1852.15 examples/s]\u001b[A\n",
      "Generating test examples...:  52%|█████▏    | 5179/10000 [00:02<00:02, 1876.04 examples/s]\u001b[A\n",
      "Generating test examples...:  54%|█████▍    | 5379/10000 [00:02<00:02, 1909.42 examples/s]\u001b[A\n",
      "Generating test examples...:  56%|█████▌    | 5585/10000 [00:02<00:02, 1952.53 examples/s]\u001b[A\n",
      "Generating test examples...:  58%|█████▊    | 5785/10000 [00:03<00:02, 1964.67 examples/s]\u001b[A\n",
      "Generating test examples...:  60%|█████▉    | 5983/10000 [00:03<00:02, 1949.81 examples/s]\u001b[A\n",
      "Generating test examples...:  62%|██████▏   | 6179/10000 [00:03<00:01, 1938.10 examples/s]\u001b[A\n",
      "Generating test examples...:  64%|██████▎   | 6374/10000 [00:03<00:01, 1937.89 examples/s]\u001b[A\n",
      "Generating test examples...:  66%|██████▌   | 6570/10000 [00:03<00:01, 1943.30 examples/s]\u001b[A\n",
      "Generating test examples...:  68%|██████▊   | 6772/10000 [00:03<00:01, 1965.52 examples/s]\u001b[A\n",
      "Generating test examples...:  70%|██████▉   | 6979/10000 [00:03<00:01, 1996.24 examples/s]\u001b[A\n",
      "Generating test examples...:  72%|███████▏  | 7183/10000 [00:03<00:01, 2007.04 examples/s]\u001b[A\n",
      "Generating test examples...:  74%|███████▍  | 7384/10000 [00:03<00:01, 2007.20 examples/s]\u001b[A\n",
      "Generating test examples...:  76%|███████▌  | 7585/10000 [00:03<00:01, 1985.08 examples/s]\u001b[A\n",
      "Generating test examples...:  78%|███████▊  | 7784/10000 [00:04<00:01, 1976.60 examples/s]\u001b[A\n",
      "Generating test examples...:  80%|███████▉  | 7982/10000 [00:04<00:01, 1917.41 examples/s]\u001b[A\n",
      "Generating test examples...:  82%|████████▏ | 8175/10000 [00:04<00:00, 1868.53 examples/s]\u001b[A\n",
      "Generating test examples...:  84%|████████▎ | 8367/10000 [00:04<00:00, 1881.21 examples/s]\u001b[A\n",
      "Generating test examples...:  86%|████████▌ | 8573/10000 [00:04<00:00, 1930.81 examples/s]\u001b[A\n",
      "Generating test examples...:  88%|████████▊ | 8776/10000 [00:04<00:00, 1959.37 examples/s]\u001b[A\n",
      "Generating test examples...:  90%|████████▉ | 8981/10000 [00:04<00:00, 1984.35 examples/s]\u001b[A\n",
      "Generating test examples...:  92%|█████████▏| 9183/10000 [00:04<00:00, 1993.82 examples/s]\u001b[A\n",
      "Generating test examples...:  94%|█████████▍| 9383/10000 [00:04<00:00, 1907.83 examples/s]\u001b[A\n",
      "Generating test examples...:  96%|█████████▌| 9575/10000 [00:05<00:00, 1911.25 examples/s]\u001b[A\n",
      "Generating test examples...:  98%|█████████▊| 9773/10000 [00:05<00:00, 1929.30 examples/s]\u001b[A\n",
      "Generating test examples...: 100%|█████████▉| 9973/10000 [00:05<00:00, 1949.94 examples/s]\u001b[A\n",
      "                                                                                          \u001b[A\n",
      "Shuffling cifar10-test.tfrecord...:   0%|          | 0/10000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling cifar10-test.tfrecord...:  87%|████████▋ | 8697/10000 [00:00<00:00, 86950.80 examples/s]\u001b[A\n",
      "\u001b[1mDataset cifar10 downloaded and prepared to /Users/beichen/tensorflow_datasets/cifar10/3.0.2. Subsequent calls will reuse this data.\u001b[0m\n",
      "data shape: (32, 32, 32, 3)\n",
      "label: tf.Tensor([0 8 8 9 6 4 7 5 2 7 4 4 3 1 8 0 2 3 0 2 4 9 8 2 8 3 8 8 2 4 4 5], shape=(32,), dtype=int64)\n",
      "An image looks like this:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.919844pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.919844\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.919844 \nL 251.565 248.919844 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 225.041719 \nL 244.365 225.041719 \nL 244.365 7.601719 \nL 26.925 7.601719 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p411ec21546)\">\n    <image height=\"218\" id=\"image1000d53fff\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-7.041719\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m492348e452\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.3225\" xlink:href=\"#m492348e452\" y=\"225.041719\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(27.14125 239.640156)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.2975\" xlink:href=\"#m492348e452\" y=\"225.041719\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(61.11625 239.640156)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"98.2725\" xlink:href=\"#m492348e452\" y=\"225.041719\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(91.91 239.640156)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"132.2475\" xlink:href=\"#m492348e452\" y=\"225.041719\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(125.885 239.640156)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"166.2225\" xlink:href=\"#m492348e452\" y=\"225.041719\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(159.86 239.640156)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"200.1975\" xlink:href=\"#m492348e452\" y=\"225.041719\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(193.835 239.640156)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"234.1725\" xlink:href=\"#m492348e452\" y=\"225.041719\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 30 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(227.81 239.640156)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mdeb4c428d8\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mdeb4c428d8\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mdeb4c428d8\" y=\"44.974219\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 48.773437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mdeb4c428d8\" y=\"78.949219\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 82.748437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mdeb4c428d8\" y=\"112.924219\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 116.723437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mdeb4c428d8\" y=\"146.899219\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 150.698437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mdeb4c428d8\" y=\"180.874219\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 184.673437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mdeb4c428d8\" y=\"214.849219\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 30 -->\n      <g transform=\"translate(7.2 218.648437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 225.041719 \nL 26.925 7.601719 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 225.041719 \nL 244.365 7.601719 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 225.041719 \nL 244.365 225.041719 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.601719 \nL 244.365 7.601719 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p411ec21546\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.601719\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "ds = tfds.load('cifar10', shuffle_files=True) # this loads a dict with the datasets\n",
    "\n",
    "# We can create an iterator from each dataset\n",
    "# This one iterates through the train data, shuffling and minibatching by 32\n",
    "train_ds = ds['train'].shuffle(1024).batch(32)\n",
    "\n",
    "# Looping through the iterator, each batch is a dict\n",
    "for batch in train_ds:\n",
    "    print(\"data shape:\", batch['image'].shape)\n",
    "    print(\"label:\", batch['label'])\n",
    "    break\n",
    "\n",
    "# visualize some of the data, pick randomly every time this cell is run\n",
    "idx = np.random.randint(batch['image'].shape[0])\n",
    "print(\"An image looks like this:\")\n",
    "imgplot = plt.imshow(batch['image'][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layers\n",
    "\n",
    "TensorFlow implements the convolutional layer with [`tf.keras.layers.Conv2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D). The function that instantiates the layer has two required arguments: number of filters and filter size. The number of filters will be equal to the number of channels in the output.\n",
    "\n",
    "Important to keep in mind is:\n",
    "\n",
    "1. Input data should be 4-dimensional with shape (batch, height, width, channels), unless the data_format argument is specified.\n",
    "2. Padding is `'valid'` by default, meaning that only filters which lie fully within the input image will be kept. This will make the resulting image slightly smaller than the input. Use `padding='same'` if image size should be preserved.\n",
    "3. Specifying `strides=n` for some n > 1 will result in an output image multiplicatively smaller than the input by a factor of n. Make sure that n isn't greater than the filter size unless you intend to completely ignore part of the input.\n",
    "\n",
    "Let's specify a convolutional classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation=tf.nn.relu, name='hidden_1')\n",
    "hidden_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation=tf.nn.relu, name='hidden_2')\n",
    "flatten = tf.keras.layers.Flatten()\n",
    "output = tf.keras.layers.Dense(10)\n",
    "conv_classifier = tf.keras.Sequential([hidden_1, hidden_2, flatten, output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This architecture of a convolutional stack followed by dense layers for classification is pretty typical. It has the major advantages of making spacially local transformations to the image, followed by a global transformation which makes the final classification decision. You might notice as well that the number of filters goes up after each convolution. This is to allow higher layers to learn more specific patterns, so we require more of them than the general patterns of the earlier layers.\n",
    "\n",
    "The number of parameters in each convolution layer can be calculated as `filter_height * filter_width * in_channels * output_channels`, as opposed to dense layers which have `input_size * output_size` parameters. For example, if we're working with CIFAR images, a first layer 3x3 convolution with 32 filters will have `3 * 3 * 3 * 32 = 864` parameters, compared to a dense layer with 32 neurons' `(32 * 32 * 3) * 32 = 98304` parameters. This is a factor of ~114 decrease, significantly smaller!\n",
    "\n",
    "We can use a function of `tf.keras.Sequential` to see more information about the network, but only after the model has been built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nhidden_1 (Conv2D)            (32, 32, 32, 32)          896       \n_________________________________________________________________\nhidden_2 (Conv2D)            (32, 32, 32, 64)          18496     \n_________________________________________________________________\nflatten_1 (Flatten)          (32, 65536)               0         \n_________________________________________________________________\ndense_1 (Dense)              (32, 10)                  655370    \n=================================================================\nTotal params: 674,762\nTrainable params: 674,762\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Run some data through the network to initialize it\n",
    "for batch in train_ds:\n",
    "    # data is uint8 by default, so we have to cast it\n",
    "    conv_classifier(tf.cast(batch['image'], tf.float32))\n",
    "    break\n",
    "conv_classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the number of channels in each output shape is equal to the number of filters in the channel. Notice also that the Flatten layer changes the shape of the data to only having two dimensions, this allows us to feed it to the Dense layer in the usual way.\n",
    "\n",
    "Let's re-create the network which we used to classify MNIST from Hackathon 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten_2 (Flatten)          (32, 3072)                0         \n_________________________________________________________________\ndense_2 (Dense)              (32, 200)                 614600    \n_________________________________________________________________\ndense_3 (Dense)              (32, 10)                  2010      \n=================================================================\nTotal params: 616,610\nTrainable params: 616,610\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "dense_classifier = tf.keras.Sequential([tf.keras.layers.Flatten(), tf.keras.layers.Dense(200), tf.keras.layers.Dense(10)])\n",
    "\n",
    "# Initialize the model\n",
    "for batch in train_ds:\n",
    "    # data is uint8 by default, so we have to cast it\n",
    "    dense_classifier(tf.cast(batch['image'], tf.float32))\n",
    "    break\n",
    "\n",
    "dense_classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This densely connected network has fewer parameters than the convolutional network! If we compare them, the one dense layer in the convolutional network has more paramters than the entire dense network. This is because the representation grows as it passes through the conv network, which is undesirable. We can handle this by summarizing the data with pooling layers. We'll add max pool layers which act similarly to conv layers, but rather than computing a function with a filter, it selects the pixel with the highest value in the window and ignores the rest.\n",
    "\n",
    "Let's respecify a larger conv network than the above, but this time with max pooling layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nhidden_1 (Conv2D)            (32, 32, 32, 32)          896       \n_________________________________________________________________\nhidden_2 (Conv2D)            (32, 32, 32, 64)          18496     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (32, 16, 16, 64)          0         \n_________________________________________________________________\nhidden_3 (Conv2D)            (32, 16, 16, 128)         73856     \n_________________________________________________________________\nhidden_4 (Conv2D)            (32, 16, 16, 256)         295168    \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (32, 8, 8, 256)           0         \n_________________________________________________________________\nflatten_3 (Flatten)          (32, 16384)               0         \n_________________________________________________________________\ndense_4 (Dense)              (32, 10)                  163850    \n=================================================================\nTotal params: 552,266\nTrainable params: 552,266\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation=tf.nn.relu, name='hidden_1')\n",
    "hidden_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation=tf.nn.relu, name='hidden_2')\n",
    "pool_1 = tf.keras.layers.MaxPool2D(padding='same')\n",
    "hidden_3 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation=tf.nn.relu, name='hidden_3')\n",
    "hidden_4 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation=tf.nn.relu, name='hidden_4')\n",
    "pool_2 = tf.keras.layers.MaxPool2D(padding='same')\n",
    "flatten = tf.keras.layers.Flatten()\n",
    "output = tf.keras.layers.Dense(10)\n",
    "conv_classifier = tf.keras.Sequential([hidden_1, hidden_2, pool_1, hidden_3, hidden_4, pool_2, flatten, output])\n",
    "\n",
    "# Run some data through the network to initialize it\n",
    "for batch in train_ds:\n",
    "    # data is uint8 by default, so we have to cast it\n",
    "    conv_classifier(tf.cast(batch['image'], tf.float32))\n",
    "    break\n",
    "conv_classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With pooling we've created a much bigger network with fewer parameters. Another way to reduce the size of the data is by setting the `stride` parameter of conv layers to be greater than one (typically two). This will have a similar effect to pooling in reducing the size of the representation by a factor of 4.\n",
    "\n",
    "### Homework\n",
    "\n",
    "Re-write your code from hackathon 2 to use convolutional layers and add code to plot a confusion matrix on the validation data.\n",
    "\n",
    "Specifically, write code to calculate a confusion matrix of the model output on the validation data, and compare to the true labels to calculate a confusion matrix with [tf.math.confusion_matrix](https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix). (For the inexperienced, [what is a confusion matrix?](https://en.wikipedia.org/wiki/Confusion_matrix)) Use the code example from [scikit-learn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html) to help visualise the confusion matrix if you'd like as well.\n",
    "\n",
    "On Canvas, submit your python code in a `.py` and your confusion matrix in a `.png` or `.txt`.\n",
    "\n",
    "I'm expecting this to take about an hour (or less if you're experienced). Feel free to use any code from this or previous hackathons. If you don't understand how to do any part of this or if it's taking you longer than that, please let me know in office hours or by email (both can be found on the syllabus). I'm also happy to discuss if you just want to ask more questions about anything in this notebook!\n",
    "\n",
    "### Coda\n",
    "\n",
    "#### Convolutional Filters from the First Layer of ImageNet\n",
    "\n",
    "Interestingly, automatically learned filters often closely resemble [Gabor Filters](https://en.wikipedia.org/wiki/Gabor_filter). The first layer of the original ImageNet network learned the following filters:\n",
    "\n",
    "![](http://smerity.com/media/images/articles/2016/imagenet_conv_kernels.png \"Convolutional Filters from the First Layer of ImageNet\")\n",
    "\n",
    "#### [Visualizing Convolutional Features](https://distill.pub/2017/feature-visualization/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('mywork': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5948cee07a8bd862e872a8ad68bfefad01def149c91ad75defc90aea373ecbbd"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}