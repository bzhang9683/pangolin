#### Hackathon 3 - Saving Models, Using Crane, and Regularization

Beichen Zhang

1. **Submitted batch job**: 32076347

2. Because the dropout rate is a given probability of each neuron in a given layer to be dropped out at each update, it does not relate to the dropped neurons' proportion. That says, even we set up the rate as 0.2, the difference between the proportions of the neurons before and after being dropped is not necessary to be 0.2.