# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kRkU2NEgsmUmm-J-vlp7yD_Vd04hvj-j
"""
import tensorflow as tf
import tensorflow_hub as hub
import tensorflow_text
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Model

module_url = "https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1"
bert_layer = hub.KerasLayer(module_url, trainable=True)

preprocessor = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3")

def build_model(bert_layer,preprocessor):
   # input_word_ids = Input(shape=(), dtype=tf.int32, name="inputs/input_mask")
   # input_mask = Input(shape=(), dtype=tf.int32, name="inputs/input_type_ids")
   # segment_ids = Input(shape=(), dtype=tf.int32, name="inputs/input_word_ids")
    
   # keys=["input_word_ids", "input_mask", "segment_ids"]
   # values=[input_word_ids, input_mask, segment_ids]
   # encoder_input = dict(zip(keys, values))
   # print(encoder_input)
    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)
    encoder_inputs = preprocessor(text_input)
    

    outputs = bert_layer(encoder_inputs)
    pooled_output = outputs["pooled_output"]      # [batch_size, 512].
 
    pooled_output = tf.keras.layers.Dropout(0.2)(pooled_output)
    out = Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))(pooled_output)

    print(out.shape)
    model = Model(inputs=text_input, outputs=out)
    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])
    
    return model

