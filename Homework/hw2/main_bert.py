# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1murq49csxyoUVRbmeN2aFlnGztLaqZSA
"""

import util
import model
from tensorflow.keras.callbacks import ModelCheckpoint
import tensorflow as tf
from sklearn.model_selection import StratifiedKFold
import numpy
#load data
X_train, y_train, X_test, y_test = util.loading_imdb()

#preprocess data
X_train_preprocessed = util.preprocessing_text(X_train.numpy())
text_input = tf.convert_to_tensor(X_train_preprocessed, dtype=tf.string)
X_test_preprocessed = util.preprocessing_text(X_test.numpy())
X_test_preprocessed_tensor = tf.convert_to_tensor(X_test_preprocessed, dtype=tf.string)


# define 10-fold cross validation test harness
seed = 7
numpy.random.seed(seed)

#save training process
checkpoint_path = "./training_checkpoints"
checkpoint = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_path, 
    verbose=1, 
    save_weights_only=True,
    monitor='loss',
    save_best_only=True,
    save_freq='epoch')

#restore weight
#checkpoint_dir = os.path.dirname(checkpoint_path)
#latest = tf.train.latest_checkpoint(checkpoint_dir)
#model.load_weights(latest)

record_accuracy=[]
record_val_accuracy=[]
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)
cvscores = []
for train, test in kfold.split(text_input, y_train):
    print(type(train))

    # create model
    model = model.build_model(model.bert_layer, model.preprocessor)
    model.summary()

	# Fit the model

    history = model.fit(
        tf.gather(text_input,train), tf.gather(y_train,train),
        epochs=25,
        validation_split=0.2,
        callbacks=[checkpoint],
        batch_size=50,
        verbose=1
    )
    #record history
    record_accuracy.append(history.history['accuracy'])
    record_val_accuracy.append(history.history['val_accuracy'])
    # evaluate the model
    scores = model.evaluate(tf.gather(text_input,test), tf.gather(y_train,test), verbose=0)
    print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
    cvscores.append(scores[1] * 100)
print("%.2f%% (+/- %.2f%%)" % (numpy.mean(cvscores), numpy.std(cvscores)))
print("record_accuray", record_accuracy)
print("record_val_accuray", record_val_accuracy)

#train model



# Visualize history
# Plot history: Loss
util.show_history(history,'loss')
util.show_history(history,'accuracy')
util.show_history(history,'val_loss')
util.show_history(history,'val_accuracy')
util.plot_diagnostics(record_accuracy, record_val_accuracy)

#Confusion matrix
y_pred = model.predict(X_test_preprocessed_tensor)
pred_label = util.initial_label(y_pred)
con_mat = tf.math.confusion_matrix(labels=y_test, predictions=pred_label).numpy()
print(con_mat)
numpy.savetxt("confusion_matrix.txt", con_mat)

#wilson confidence interval
#95% 1.96
#error +/- const * sqrt( (error * (1 - error)) / n)
score = model.evaluate(X_test_preprocessed_tensor,y_test, verbose=0)
print("The loss of test data:%.2f; the accuracy of test data:%.2f:" % (score[0], score[1]))
n = X_test_preprocessed_tensor.shape[0]

low, high = util.confidence_interval(score[1],n)
print("95%% confidence interval:[%.1f%%, %.1f%%]:" % (low*100, high*100))
# ## save model and restore

# In[ ]:


tf.saved_model.save(model, './saved_model')

